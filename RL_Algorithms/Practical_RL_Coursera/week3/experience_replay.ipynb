{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experience_replay.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIQzkWAC2X4Y",
        "colab_type": "text"
      },
      "source": [
        "### Honor Track: experience replay\n",
        "\n",
        "There's a powerful technique that you can use to improve sample efficiency for off-policy algorithms: [spoiler] Experience replay :)\n",
        "\n",
        "The catch is that you can train Q-learning and EV-SARSA on `<s,a,r,s'>` tuples even if they aren't sampled under current agent's policy. So here's what we're gonna do:\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/exp_replay.png width=480>\n",
        "\n",
        "#### Training with experience replay\n",
        "1. Play game, sample `<s,a,r,s'>`.\n",
        "2. Update q-values based on `<s,a,r,s'>`.\n",
        "3. Store `<s,a,r,s'>` transition in a buffer. \n",
        " 3. If buffer is full, delete earliest data.\n",
        "4. Sample K such transitions from that buffer and update q-values based on them.\n",
        "\n",
        "\n",
        "To enable such training, first we must implement a memory structure that would act like such a buffer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kznWIHK2X4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9aa98763-2c86-441e-bb21-cad942783700"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring20/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adRXsAGU2X4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9c-UXmF2X4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "\n",
        "class QLearningAgent():\n",
        "  def __init__(self, alpha, discount, epsilon, get_legal_actions):\n",
        "    self.alpha = alpha\n",
        "    self.discount = discount\n",
        "    self.epsilon = epsilon\n",
        "    self.get_legal_actions = get_legal_actions\n",
        "    self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "  def get_qvalue(self, state, action):\n",
        "    return self._qvalues[state][action]\n",
        "\n",
        "  def set_qvalue(self, state, action, value):\n",
        "    self._qvalues[state][action] = value\n",
        "  \n",
        "  def get_value(self, state):\n",
        "    possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "    if len(possible_actions) == 0:\n",
        "      return 0.0\n",
        "\n",
        "    return max([self.get_qvalue(state, a) for a in possible_actions])\n",
        "  \n",
        "  def update(self, state, action, reward, next_state):\n",
        "    gamma = self.discount\n",
        "    learning_rate = self.alpha\n",
        "\n",
        "    value = (1-learning_rate)*self.get_qvalue(state, action) + learning_rate*(reward + gamma*self.get_value(next_state))\n",
        "\n",
        "    self.set_qvalue(state, action, value)\n",
        "  \n",
        "  def get_best_action(self, state):\n",
        "    possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "    if len(possible_actions) == 0:\n",
        "      return None\n",
        "\n",
        "    return possible_actions[np.argmax([self.get_qvalue(state, a) for a in possible_actions])]\n",
        "  \n",
        "  def get_action(self, state):\n",
        "    epsilon = self.epsilon\n",
        "    choice = random.random()\n",
        "    possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "    if len(possible_actions) == 0:\n",
        "      return None\n",
        "\n",
        "    if choice < epsilon:\n",
        "      return random.choice(possible_actions)\n",
        "    else:\n",
        "      return self.get_best_action(state)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Ee_Bdu2X43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size):\n",
        "        \"\"\"\n",
        "        Create Replay buffer.\n",
        "        Parameters\n",
        "        ----------\n",
        "        size: int\n",
        "            Max number of transitions to store in the buffer. When the buffer\n",
        "            overflows the old memories are dropped.\n",
        "\n",
        "        Note: for this assignment you can pick any data structure you want.\n",
        "              If you want to keep it simple, you can store a list of tuples of (s, a, r, s') in self._storage\n",
        "              However you may find out there are faster and/or more memory-efficient ways to do so.\n",
        "        \"\"\"\n",
        "        self._storage = []\n",
        "        self._maxsize = size\n",
        "\n",
        "        # OPTIONAL: YOUR CODE\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._storage)\n",
        "\n",
        "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
        "        '''\n",
        "        Make sure, _storage will not exceed _maxsize. \n",
        "        Make sure, FIFO rule is being followed: the oldest examples has to be removed earlier\n",
        "        '''\n",
        "        data = (obs_t, action, reward, obs_tp1, done)\n",
        "        \n",
        "        if len(self._storage) == self._maxsize:\n",
        "          self._storage.pop()\n",
        "          \n",
        "\n",
        "        # add data to storage\n",
        "        self._storage.insert(0, data)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Sample a batch of experiences.\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size: int\n",
        "            How many transitions to sample.\n",
        "        Returns\n",
        "        -------\n",
        "        obs_batch: np.array\n",
        "            batch of observations\n",
        "        act_batch: np.array\n",
        "            batch of actions executed given obs_batch\n",
        "        rew_batch: np.array\n",
        "            rewards received as results of executing act_batch\n",
        "        next_obs_batch: np.array\n",
        "            next set of observations seen after executing act_batch\n",
        "        done_mask: np.array\n",
        "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
        "            the end of an episode and 0 otherwise.\n",
        "        \"\"\"\n",
        "        idxes = [random.choice(range(self.__len__())) for _ in range(batch_size)]\n",
        "\n",
        "        # collect <s,a,r,s',done> for each index\n",
        "        states, actions, rewards, next_state, done = [], [], [], [], []\n",
        "        for i in idxes:\n",
        "          states.append(self._storage[i][0])\n",
        "          actions.append(self._storage[i][1])\n",
        "          rewards.append(self._storage[i][2])\n",
        "          next_state.append(self._storage[i][3])\n",
        "          done.append(self._storage[i][4])\n",
        "\n",
        "        return (\n",
        "            np.array( states ),\n",
        "            np.array( actions ),\n",
        "            np.array( rewards ),\n",
        "            np.array( next_state ),\n",
        "            np.array( done )\n",
        "        )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZFtprx12X49",
        "colab_type": "text"
      },
      "source": [
        "Some tests to make sure your buffer works right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W2plpU52X4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "405b6136-55e8-4ae5-dad7-b7e1c8a85306"
      },
      "source": [
        "def obj2arrays(obj):\n",
        "    for x in obj:\n",
        "        yield np.array([x])\n",
        "\n",
        "def obj2sampled(obj):\n",
        "    return tuple(obj2arrays(obj))\n",
        "\n",
        "replay = ReplayBuffer(2)\n",
        "obj1 = (0, 1, 2, 3, True)\n",
        "obj2 = (4, 5, 6, 7, False)\n",
        "replay.add(*obj1)\n",
        "assert replay.sample(1) == obj2sampled(obj1), \\\n",
        "    \"If there's just one object in buffer, it must be retrieved by buf.sample(1)\"\n",
        "replay.add(*obj2)\n",
        "assert len(replay) == 2, \"Please make sure __len__ methods works as intended.\"\n",
        "replay.add(*obj2)\n",
        "assert len(replay) == 2, \"When buffer is at max capacity, replace objects instead of adding new ones.\"\n",
        "assert tuple(np.unique(a) for a in replay.sample(100)) == obj2sampled(obj2)\n",
        "replay.add(*obj1)\n",
        "assert max(len(np.unique(a)) for a in replay.sample(100)) == 2\n",
        "replay.add(*obj1)\n",
        "assert tuple(np.unique(a) for a in replay.sample(100)) == obj2sampled(obj1)\n",
        "print(\"Success!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb2HHJgY2X5C",
        "colab_type": "text"
      },
      "source": [
        "Now let's use this buffer to improve training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGQjvU4Y2X5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "\n",
        "try:\n",
        "    env = gym.make('Taxi-v3')\n",
        "except gym.error.DeprecatedEnv:\n",
        "    # Taxi-v2 was replaced with Taxi-v3 in gym 0.15.0\n",
        "    env = gym.make('Taxi-v2')\n",
        "\n",
        "n_actions = env.action_space.n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6dhOY9R2X5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play_and_train_with_replay(env, agent, replay=None,\n",
        "                               t_max=10**4, replay_batch_size=32):\n",
        "    \"\"\"\n",
        "    This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\n",
        "    :param replay: ReplayBuffer where agent can store and sample (s,a,r,s',done) tuples.\n",
        "        If None, do not use experience replay\n",
        "    \"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # get agent to pick action given state s\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "\n",
        "        # update agent on current transition. Use agent.update\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        if replay is not None:\n",
        "            # store current <s,a,r,s'> transition in buffer\n",
        "            replay.add(s, a, r, next_s, done)\n",
        "\n",
        "            # sample replay_batch_size random transitions from replay,\n",
        "            # then update agent on each of them in a loop\n",
        "            s_, a_, r_, next_s_, done_ = replay.sample(replay_batch_size)\n",
        "            for i in range(replay_batch_size):\n",
        "                agent.update(s_[i], a_[i], r_[i], next_s_[i])\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8PMgFF22X5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create two agents: first will use experience replay, second will not.\n",
        "\n",
        "agent_baseline = QLearningAgent(\n",
        "    alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "    get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_replay = QLearningAgent(\n",
        "    alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "    get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "replay = ReplayBuffer(1000)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVUu9rfE2X5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "bc2fd413-af51-42d2-901d-42077c09545a"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_replay, rewards_baseline = [], []\n",
        "\n",
        "for i in range(1000):\n",
        "    rewards_replay.append(\n",
        "        play_and_train_with_replay(env, agent_replay, replay))\n",
        "    rewards_baseline.append(\n",
        "        play_and_train_with_replay(env, agent_baseline, replay=None))\n",
        "\n",
        "    agent_replay.epsilon *= 0.99\n",
        "    agent_baseline.epsilon *= 0.99\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('Baseline : eps =', agent_replay.epsilon,\n",
        "              'mean reward =', np.mean(rewards_baseline[-10:]))\n",
        "        print('ExpReplay: eps =', agent_baseline.epsilon,\n",
        "              'mean reward =', np.mean(rewards_replay[-10:]))\n",
        "        plt.plot(moving_average(rewards_replay), label='exp. replay')\n",
        "        plt.plot(moving_average(rewards_baseline), label='baseline')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline : eps = 2.9191091959171894e-05 mean reward = 7.8\n",
            "ExpReplay: eps = 2.9191091959171894e-05 mean reward = 7.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyXUudl42X5Q",
        "colab_type": "text"
      },
      "source": [
        "### Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gBzEuP2X5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8668606-b48f-4354-fa62-085410da24bd"
      },
      "source": [
        "from submit import submit_experience_replay\n",
        "submit_experience_replay(rewards_replay, rewards_baseline, 'atharvaprakash99@gmail.com', 'ouV5mCAmEW3vKJvh')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7BJEy7o2X5V",
        "colab_type": "text"
      },
      "source": [
        "#### What to expect:\n",
        "\n",
        "Experience replay, if implemented correctly, will improve algorithm's initial convergence a lot, but it shouldn't affect the final performance.\n",
        "\n",
        "### Outro\n",
        "\n",
        "We will use the code you just wrote extensively in the next week of our course. If you're feeling that you need more examples to understand how experience replay works, try using it for binarized state spaces (CartPole or other __[classic control envs](https://gym.openai.com/envs/#classic_control)__).\n",
        "\n",
        "__Next week__ we're gonna explore how q-learning and similar algorithms can be applied for large state spaces, with deep learning models to approximate the Q function.\n",
        "\n",
        "However, __the code you've written__ for this week is already capable of solving many RL problems, and as an added benifit - it is very easy to detach. You can use Q-learning, SARSA and Experience Replay for any RL problems you want to solve - just thow 'em into a file and import the stuff you need."
      ]
    }
  ]
}