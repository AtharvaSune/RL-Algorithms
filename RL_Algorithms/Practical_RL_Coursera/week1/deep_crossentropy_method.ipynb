{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "deep_crossentropy_method.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr-WQuV9eKi_",
        "colab_type": "text"
      },
      "source": [
        "# Deep Crossentropy method\n",
        "\n",
        "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
        "\n",
        "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYqvPGCWeKjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96d85499-c4ee-48fe-ec58-5694ab857e7b"
      },
      "source": [
        "# In Google Colab, uncomment this:\n",
        "!wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py\n",
        "\n",
        "# XVFB will be launched if you run on a server\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-18 10:42:38--  https://bit.ly/2FMJP5K\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring19/setup_colab.sh [following]\n",
            "--2020-06-18 10:42:38--  https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring19/setup_colab.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262 [text/plain]\n",
            "Saving to: ‘setup.py’\n",
            "\n",
            "\rsetup.py              0%[                    ]       0  --.-KB/s               \rsetup.py            100%[===================>]     262  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-18 10:42:38 (11.2 MB/s) - ‘setup.py’ saved [262/262]\n",
            "\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/ca/20aee170afe6011e295e34b27ad7d7ccd795faba581dd3c6f7cec237f561/pyglet-1.5.0-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.2.4\n",
            "    Uninstalling pyglet-1.2.4:\n",
            "      Successfully uninstalled pyglet-1.2.4\n",
            "Successfully installed pyglet-1.5.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 43 not upgraded.\n",
            "--2020-06-18 10:42:43--  https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/xvfb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640 [text/plain]\n",
            "Saving to: ‘../xvfb’\n",
            "\n",
            "../xvfb             100%[===================>]     640  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-18 10:42:44 (7.87 MB/s) - ‘../xvfb’ saved [640/640]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 43 not upgraded.\n",
            "Collecting pyglet==1.2.4\n",
            "  Using cached https://files.pythonhosted.org/packages/68/c3/300c6f92b21886b0fe42c13f3a39a06c6cb90c9fbb1b71da85fe59091a7d/pyglet-1.2.4-py3-none-any.whl\n",
            "\u001b[31mERROR: gym 0.17.2 has requirement pyglet<=1.5.0,>=1.4.0, but you'll have pyglet 1.2.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "Successfully installed pyglet-1.2.4\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdQ5IO1VeKjM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2ddb376d-e795-486f-888d-77a750afff55"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
        "env = gym.make(\"CartPole-v0\").env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "# plt.imshow(env.render(\"rgb_array\"))\n",
        "print(\"state vector dim =\", state_dim)\n",
        "print(\"n_actions =\", n_actions)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state vector dim = 4\n",
            "n_actions = 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odF9hhpOeKjU",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network Policy\n",
        "\n",
        "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
        "\n",
        "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
        "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyz-Dr5aeKjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "64ca1758-0b67-4d0b-852b-246a6eb1d08f"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "agent = MLPClassifier(\n",
        "    hidden_layer_sizes=(20, 20),\n",
        "    activation='tanh',\n",
        ")\n",
        "\n",
        "# initialize agent to the dimension of state space and number of actions\n",
        "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmZtGuOceKjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_session(agent, t_max=1000):\n",
        "    \"\"\"\n",
        "    Play a single game using agent neural network.\n",
        "    Terminate when game finishes or after :t_max: steps\n",
        "    \"\"\"\n",
        "    states, actions = [], []\n",
        "    total_reward = 0\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        \n",
        "        # use agent to predict a vector of action probabilities for state :s:\n",
        "        probs = agent.predict_proba([s])[0]\n",
        "\n",
        "        assert probs.shape == (n_actions,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
        "        \n",
        "        # use the probabilities you predicted to pick an action\n",
        "        # sample proportionally to the probabilities, don't just take the most likely action\n",
        "        a = np.random.choice(n_actions, 1, p=probs)[0]\n",
        "        # ^-- hint: try np.random.choice\n",
        "\n",
        "        new_s, r, done, info = env.step(a)\n",
        "\n",
        "        # record sessions like you did before\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        total_reward += r\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "    return states, actions, total_reward"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVOeOCgteKjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b343ffb8-89fc-4de4-ee01-c286cd2028f8"
      },
      "source": [
        "dummy_states, dummy_actions, dummy_reward = generate_session(agent, t_max=5)\n",
        "print(\"states:\", np.stack(dummy_states))\n",
        "print(\"actions:\", dummy_actions)\n",
        "print(\"reward:\", dummy_reward)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "states: [[-8.89902840e-05  6.55827800e-03 -1.23846524e-02  2.38916941e-02]\n",
            " [ 4.21752760e-05  2.01855627e-01 -1.19068185e-02 -2.72672858e-01]\n",
            " [ 4.07928781e-03  6.90557892e-03 -1.73602757e-02  1.62309631e-02]\n",
            " [ 4.21739938e-03 -1.87963158e-01 -1.70356564e-02  3.03386358e-01]\n",
            " [ 4.58136221e-04 -3.82838232e-01 -1.09679293e-02  5.90648313e-01]]\n",
            "actions: [1, 0, 0, 0, 1]\n",
            "reward: 5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIyL0BQIeKjo",
        "colab_type": "text"
      },
      "source": [
        "### CEM steps\n",
        "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
        "\n",
        "The only difference is that now each observation is not a number but a `float32` vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgPi6yKseKjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
        "    \"\"\"\n",
        "    Select states and actions from games that have rewards >= percentile\n",
        "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\n",
        "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
        "\n",
        "    Please return elite states and actions in their original order \n",
        "    [i.e. sorted by session number and timestep within session]\n",
        "\n",
        "    If you are confused, see examples below. Please don't assume that states are integers\n",
        "    (they will become different later).\n",
        "    \"\"\"\n",
        "\n",
        "    rewards_threshold = np.percentile(rewards_batch, percentile)\n",
        "    elite_states = [s for i in range(len(states_batch)) if rewards_batch[i] >= rewards_threshold for s in states_batch[i]]\n",
        "    elite_actions = [a for i in range(len(actions_batch)) if rewards_batch[i] >= rewards_threshold for a in actions_batch[i]]\n",
        "    \n",
        "    return elite_states, elite_actions"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxuuL1sEeKjt",
        "colab_type": "text"
      },
      "source": [
        "# Training loop\n",
        "Generate sessions, select N best and fit to those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7kc4qrFeKju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
        "    \"\"\"\n",
        "    A convenience function that displays training progress. \n",
        "    No cool math here, just charts.\n",
        "    \"\"\"\n",
        "\n",
        "    mean_reward = np.mean(rewards_batch)\n",
        "    threshold = np.percentile(rewards_batch, percentile)\n",
        "    log.append([mean_reward, threshold])\n",
        "\n",
        "    clear_output(True)\n",
        "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
        "    plt.figure(figsize=[8, 4])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
        "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(rewards_batch, range=reward_range)\n",
        "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
        "               [0], [100], label=\"percentile\", color='red')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3dXkcCIeKjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "c40fceab-ec90-4c83-f0ce-241836818973"
      },
      "source": [
        "n_sessions = 100\n",
        "percentile = 70\n",
        "log = []\n",
        "\n",
        "for i in range(100):\n",
        "    # generate new sessions\n",
        "    sessions = [generate_session(agent) for _ in range(n_sessions)]\n",
        "\n",
        "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
        "\n",
        "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch)\n",
        "\n",
        "    agent.fit(elite_states, elite_actions)\n",
        "\n",
        "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
        "\n",
        "    if np.mean(rewards_batch) > 190:\n",
        "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean reward = 307.830, threshold=368.800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "You Win! You may stop training now via KeyboardInterrupt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-177abf8c8f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-177abf8c8f32>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-472c92866e87>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(agent, t_max)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# use agent to predict a vector of action probabilities for state :s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"make sure probabilities are a vector (hint: np.reshape)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \"\"\"\n\u001b[1;32m   1071\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \"\"\"\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;31m# Make sure self.hidden_layer_sizes is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflexible\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m             warnings.warn(\n\u001b[1;32m    561\u001b[0m                 \u001b[0;34m\"Beginning in version 0.22, arrays of bytes/strings will be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \"\"\"\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB9LSdHFeKjz",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZAtZKpHeKj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "b318d199-e9bd-4c7b-ce04-2e29d5fbcfd9"
      },
      "source": [
        "# record sessions\n",
        "import gym.wrappers\n",
        "env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"),\n",
        "                           directory=\"videos\", force=True)\n",
        "sessions = [generate_session(env) for _ in range(100)]\n",
        "env.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cf45638fd0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"),\n\u001b[1;32m      4\u001b[0m                            directory=\"videos\", force=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-cf45638fd0d5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"),\n\u001b[1;32m      4\u001b[0m                            directory=\"videos\", force=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-472c92866e87>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(agent, t_max)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_after_reset\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# Bump *after* all reset activity has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset_video_recorder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_video_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitoring/video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mrender_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ansi'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mansi_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_buffer_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_color_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# In https://github.com/openai/gym-http-api/issues/2, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# discovered that someone using Xmonad on Arch was having\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get_data() missing 2 required positional arguments: 'format' and 'pitch'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Boba9XCaeKj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show video\n",
        "from IPython.display import HTML\n",
        "import os\n",
        "\n",
        "video_names = list(\n",
        "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(\"./videos/\"+video_names[-1]))  # this may or may not be _last_ video. Try other indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fedhMSEEeKj-",
        "colab_type": "text"
      },
      "source": [
        "# Homework part I\n",
        "\n",
        "### Tabular crossentropy method\n",
        "\n",
        "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
        "\n",
        "### Tasks\n",
        "- __1.1__ (1 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`.\n",
        "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
        "\n",
        "It's okay to modify the existing code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2L527XweKj-",
        "colab_type": "text"
      },
      "source": [
        "```<Describe what you did here.  Preferably with plot/report to support it.>```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01zR5ZsjeKj_",
        "colab_type": "text"
      },
      "source": [
        "# Homework part II\n",
        "\n",
        "### Deep crossentropy method\n",
        "\n",
        "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
        "\n",
        "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
        "  * For MountainCar, get average reward of __at least -150__\n",
        "  * For LunarLander, get average reward of __at least +50__\n",
        "\n",
        "See the tips section below, it's kinda important.\n",
        "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
        "  \n",
        "  \n",
        "* __2.2__ (up to 6 pt) Devise a way to speed up training against the default version\n",
        "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
        "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
        "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
        "  \n",
        "__Please list what you did in anytask submission form__. __It's necessary to measure your improvement experimentally__.  __You score depends on this improvement. If the algorithm converges 2x faster, you obtain 3 pts. If the algorithm converges 4x faster, you obtain 6pts__.\n",
        "  \n",
        "  \n",
        "### Tips\n",
        "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0), [LunarLander](https://gym.openai.com/envs/LunarLander-v2)\n",
        "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
        " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
        "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
        "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
        "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
        "* 20-neuron network is probably not enough, feel free to experiment.\n",
        "\n",
        "You may find the following snippet useful:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw9N-o-5eKj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_mountain_car(env, agent):\n",
        "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
        "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
        "    grid = np.dstack(np.meshgrid(xs, vs)).transpose(1, 0, 2)\n",
        "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
        "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3)\n",
        "    return probs\n",
        "\n",
        "plt.imshow(visualize_mountain_car(env, agent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6u6BnqFeKkC",
        "colab_type": "text"
      },
      "source": [
        "### Bonus tasks\n",
        "\n",
        "* __2.3 bonus__ (2 pts) Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
        "\n",
        "* __2.4 bonus__ (4 pts) Solve continuous action space task with `MLPRegressor` or similar.\n",
        "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
        "  * Choose one of [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0) (90+ pts to solve), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) (200+ pts to solve) \n",
        "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
        "\n",
        "\n",
        "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6JmL0DSeKkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}